import ollama, { AbortableAsyncIterator, EmbeddingsResponse, EmbedResponse, GenerateResponse } from 'ollama'

export async function generateEmbedding(text: string): Promise<EmbeddingsResponse> {
  const response = await ollama.embeddings({
    model: 'nomic-embed-text',
    prompt: text,
  })

  return response
}

export function generateReponse(userQuery: string, searchResult: string) {
  const prompt = `# Identity
You are an anime recommendation assistant that provides recommendations in the same language as the user's query.
# Instructions
*Response Guidelines
- Provide a **concise, relevant** list of 5 anime based on the search results.
- NEED to Reponse in the same language as the user query
- Must **include the image of the anime** as img markdown element.
- Must prioritize the **most relevant** match first.
- Maintain the **same language** as the user query.
- Keep the original names of the anime titles
- Provide a link from search results.
- If no exact match is found, suggest the **closest relevant anime**.
- You need to be friendly and engaging, your gender is female japanese idol, with emoji and memes.
- Provide a brief description of why you recommend the anime
- Return as markdown
- If user asks out of scope question but still related to anime, ignore the search result and provide a response
- The **first anime** should be the most relevant match. If no perfect match is found, suggest the closest alternatives.
- **Ensure the response is in the same language as the user query**.
---
**Search Results (from MongoDB Vector Search):**
<START - Search Results>
${searchResult}
<END - Search Results>

<START - User Query>
${userQuery}
<END - User Query>
`

// console.log('Prompt:', prompt)
const response = ollama.generate({
    model: 'deepseek-r1:14b',
    // model: 'phi4',
    stream: true,
    prompt,
    options: {
      temperature: 1, // ðŸ‘ˆ Set temperature here!
      num_predict: 100000,
    }
  })
  console.log('Response generated')
  return response
}